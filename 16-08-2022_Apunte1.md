>Bases de datos 2
>16-08-2022
>Pamela González López - 2019390545

# **MapReduce**

Es un sistema distribuido, en estos sistemas lo que se tiene son varios servidores "workers", la red y un coordinador que recibe la solicitud de un usuario. Cuando es recibida esta solicitud, toma el big data, se inicia el procesamiento y se especifica el "partition size".

El coordinador asigna particiones a cada uno de los workers, por lo general, son asignadas a más de uno. Las particiones pequeñas, aquellas que puedan leer y procesar memoria en un solo tracto son mejores cuando se habla de computación distribuida.

![N|Solid](https://i.pinimg.com/originals/e7/f5/6e/e7f56ebb88b21dd2449d6f70a0729611.jpg)

En cuanto a la red se utiliza Ethernet (protocolo de capa de acceso al medio que se encarga de mover datos). La cual está esparcida regionalmente.

**Ilustrando lo que es una red regional:**

![N|Solid](https://i.pinimg.com/originals/1e/15/10/1e1510c02c207510dc12e4a90530c55b.jpg)

¿Dónde se genera un cuello de botella a nivel de rendimiento y procesamiento?

Cuando se empiezan a realizar muchas transacciones a disco, aumenta operaciones de entrada y salida como el tráfico de red.

Se puede observar en el comportamiento de la memoria cuando está cercana al 100% y el CPU se mantiene 100%.

**Ilustrando:**

![N|Solid](https://i.pinimg.com/originals/5e/fe/19/5efe196e7d7f5bebaccc76cb9157c0f8.jpg)

# **Shard**

En bases de datos, en especial NoSQL tenemos el concepto de shard.

NoSQL Partition = Shard

La idea del shard en BD, es que sea algo que pueda entrar en memoria completamente. 

¿Qué es lo que viene a causar un shard a nivel de BD?

Cuando se parte la info en shards, estos deberían distribuirse dentro de todos los workers que tenemos pues cuando un usuario hace una consulta, esta consulta debe ejecutarse en todas las réplicas por igual. Los nodos van a obtener el resultado de la consulta y cada vez que se obtiene dicho resultado se devuelve a un nodo (que se escoge como el coordinador) y esa info se envía al usuario final. 

SQL = Partitions = Shards = NoSQL (Los partitions toman el datasets y lo parten en pedacitos).

Partitions NoSQL: Se hacen a partir de una condición. Por ejemplo, por fechas.

**Ilustrando:**

![N|Solid](https://i.pinimg.com/originals/08/f5/9c/08f59c1245f24afe3f232eb1249fe2c8.jpg)

# **Infrastructure Services, Container Services y Managed Services:**

![N|Solid](https://d2908q01vomqb2.cloudfront.net/c5b76da3e608d34edb07244cd9b875ee86906328/2020/12/28/Shared-Responsibility-by-Service-Type.png)


# **Spark**

En su versión Spark SQL se comporta como una base de datos NoSQL.

* Spark puede leer diferentes archivos. Por ejemplo, utilizando un csv, se debe especificar: Delimitador del archivo, el quote que se va a utilizar, el header y multiline.

* Tiene un transformations chaining

Las transformaciones están asociadas unas con otras, por sí solas no hacen nada por lo cual debe existir un evento para que estas transformaciones se disparen.

**Ilustrando:**

![N|Solid](https://i.pinimg.com/originals/bf/e1/57/bfe1579c6ed241fc75c3bcc8d23d5af1.jpg)

Es común que en la parte de "Action" el usuario utilice: count, show, select, etc.

Para no tener que estar recalculando datos se puede:

* Usar el comando persist, este se ejecuta sobre una operación o transformación específica. Corta el transformation chaining dejando en memoria los datos procesados o datos refinados, esto con el fin de que los datos no se vuelvan a recalcular.

* Otra manera sería guardando los datos y volverlos a leer. En el momento que se escribe y se lee se empieza un nuevo árbol de transformaciones.

Spark tiene todas las características de otras bases de datos. Utiliza la teoría de conjuntos al igual que MySQL, SQL Server, etc.

Se puede trabajar con select, where, con joins, ordenamientos (order by, group by), etc.

